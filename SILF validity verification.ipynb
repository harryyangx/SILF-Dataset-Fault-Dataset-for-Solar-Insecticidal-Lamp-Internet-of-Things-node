{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45d14917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from matplotlib.ticker import FuncFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1aaacab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "file_path = 'output.xlsx' # use your own path\n",
    "data = pd.read_excel(file_path)\n",
    "data['Time'] = data['Time'].dt.hour # Only retain the hourly data in the time data as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "909c7b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to the large number of fault free (F0) samples, only 10% of the samples labeled as' F0 'are retained\n",
    "df_f0 = data[data['Fault'] == 'F0']\n",
    "df_other = data[data['Fault'] != 'F0']\n",
    "df_f0_sampled = df_f0.sample(frac=0.1, random_state=42)\n",
    "df_balanced = pd.concat([df_f0_sampled, df_other])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53b1795a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove categories with low sample size (not exceed 20)\n",
    "category_counts = df_balanced['Fault'].value_counts() # Calculate the sample size for each category\n",
    "valid_categories = category_counts[category_counts > 20].index # Filter out categories with a sample size greater than 20\n",
    "filtered_df = df_balanced[df_balanced['Fault'].isin(valid_categories)] # Filter the original DataFrame and retain categories with a sample size greater than 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c18b3e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = filtered_df.sample(frac=1, random_state=42).reset_index(drop=True) # Disrupt data\n",
    "# Feature and label separation\n",
    "X = df_balanced.drop(columns=['Fault'])\n",
    "y = df_balanced['Fault']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c771218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation indicators and parameter settings\n",
    "def evaluate_model(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    precision = precision_score(y, y_pred, average='macro', zero_division=0)\n",
    "    recall = recall_score(y, y_pred, average='macro', zero_division=0)\n",
    "    f1 = f1_score(y, y_pred, average='macro', zero_division=0)\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "152635d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-fold cross validation training and evaluation\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"SVM\": SVC(probability=True, random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Naive Bayes\": GaussianNB()\n",
    "}\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42) # Set K-fold cross validation\n",
    "results = {model: {'accuracy': [], 'precision': [], 'recall': [], 'f1': []} for model in models} # Store the evaluation results of each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe18765e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Model Training and Validation\n",
    "for model_name, model in models.items():\n",
    "    for train_idx, val_idx in kf.split(X, y):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        model.fit(X_train, y_train) # Train model\n",
    "        # validate model\n",
    "        accuracy, precision, recall, f1 = evaluate_model(model, X_val, y_val)\n",
    "        results[model_name]['accuracy'].append(accuracy)\n",
    "        results[model_name]['precision'].append(precision)\n",
    "        results[model_name]['recall'].append(recall)\n",
    "        results[model_name]['f1'].append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "237d4949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average evaluation metrics for each model\n",
    "avg_results = {model: {metric: np.mean(results[model][metric]) for metric in results[model]} for model in models}\n",
    "avg_results_df = pd.DataFrame(avg_results)\n",
    "# Output the DataFrame to an Excel file\n",
    "avg_results_df.to_excel('average_result.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d897289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ExcelWriter object to save multiple sheets\n",
    "with pd.ExcelWriter('all_result.xlsx') as writer:\n",
    "    # Traverse every sheet in the dictionary\n",
    "    for sheet_name, data in results.items():\n",
    "        # Convert internal dictionary to DataFrame\n",
    "        results_df = pd.DataFrame(data)\n",
    "        # Write the DataFrame to the corresponding sheet in Excel\n",
    "        results_df.to_excel(writer, sheet_name=sheet_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97345f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for Random Forest has been saved to 'confusion_matrix.xlsx' sheet.\n",
      "Confusion matrix for SVM has been saved to 'confusion_matrix.xlsx' sheet.\n",
      "Confusion matrix for KNN has been saved to 'confusion_matrix.xlsx' sheet.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for Logistic Regression has been saved to 'confusion_matrix.xlsx' sheet.\n",
      "Confusion matrix for Decision Tree has been saved to 'confusion_matrix.xlsx' sheet.\n",
      "Confusion matrix for Naive Bayes has been saved to 'confusion_matrix.xlsx' sheet.\n"
     ]
    }
   ],
   "source": [
    "# Draw a confusion matrix heatmap\n",
    "with pd.ExcelWriter('confusion_matrix.xlsx', engine='openpyxl') as writer:\n",
    "    for model_name, model in models.items():\n",
    "        # Select the validation set for the last fold\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "        cm = confusion_matrix(y_val, y_pred, labels=model.classes_)\n",
    "        # Convert the confusion matrix into a DataFrame\n",
    "        cm_df = pd.DataFrame(cm, index=model.classes_, columns=model.classes_) \n",
    "        # Save the confusion matrix of each model to the corresponding sheet, which is named the model name\n",
    "        cm_df.to_excel(writer, sheet_name=model_name)\n",
    "        \n",
    "        print(f\"Confusion matrix for {model_name} has been saved to 'confusion_matrix.xlsx' sheet.\")   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
